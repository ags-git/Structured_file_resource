# Задание
Напиши модуль UNIT тестирования для проверки корректности модуля сканирования файловой системы синхронной версии.

# Модуль UNIT тестирования для синхронной версии сканера файловой системы

```python
# tests/test_scanner_sync.py
import unittest
import os
import tempfile
import shutil
from pathlib import Path
import hashlib
import psycopg2
from unittest.mock import patch, MagicMock
import time
from datetime import datetime

from scanner.config import ScannerConfig
from scanner.database import Database
from scanner.scanner import FileSystemScanner
from scanner.models import DirectoryItem, FileItem
from scanner.hash_calculator import HashCalculator

class TestHashCalculator(unittest.TestCase):
    def setUp(self):
        # Создаем временную директорию для тестовых файлов
        self.temp_dir = tempfile.mkdtemp()
        self.hash_calculator = HashCalculator(chunk_size=1024)

    def tearDown(self):
        # Удаляем временную директорию после завершения тестов
        shutil.rmtree(self.temp_dir)

    def test_calculate_md5_small_file(self):
        # Создаем тестовый файл с известным содержимым
        test_file = Path(self.temp_dir) / "test_small.txt"
        content = "test content"
        test_file.write_text(content)

        # Вычисляем MD5 хеш
        calculated_hash = self.hash_calculator.calculate_md5(test_file)

        # Проверяем результат
        expected_hash = hashlib.md5(content.encode()).hexdigest()
        self.assertEqual(calculated_hash, expected_hash)

    def test_calculate_md5_large_file(self):
        # Создаем файл размером больше chunk_size
        test_file = Path(self.temp_dir) / "test_large.txt"
        content = "x" * 2048  # Размер больше chunk_size (1024)
        test_file.write_text(content)

        # Вычисляем MD5 хеш
        calculated_hash = self.hash_calculator.calculate_md5(test_file)

        # Проверяем результат
        expected_hash = hashlib.md5(content.encode()).hexdigest()
        self.assertEqual(calculated_hash, expected_hash)

    def test_calculate_md5_nonexistent_file(self):
        # Проверяем обработку несуществующего файла
        test_file = Path(self.temp_dir) / "nonexistent.txt"
        calculated_hash = self.hash_calculator.calculate_md5(test_file)

        # Должен вернуть None
        self.assertIsNone(calculated_hash)

    def test_calculate_md5_empty_file(self):
        # Проверяем обработку пустого файла
        test_file = Path(self.temp_dir) / "empty.txt"
        test_file.touch()

        # Вычисляем MD5 хеш
        calculated_hash = self.hash_calculator.calculate_md5(test_file)

        # Проверяем результат
        expected_hash = hashlib.md5(b"").hexdigest()
        self.assertEqual(calculated_hash, expected_hash)

class TestDatabaseMocked(unittest.TestCase):
    def setUp(self):
        # Создаем мок для соединения с базой данных
        self.mock_conn = MagicMock()
        self.mock_cursor = MagicMock()
        self.mock_conn.cursor.return_value = self.mock_cursor

        # Создаем экземпляр класса Database с мок соединением
        self.database = Database("dummy_dsn")
        self.database._conn = self.mock_conn

    def test_mark_items_not_actual(self):
        # Тестируем метод mark_items_not_actual
        resource_id = 1
        self.database.mark_items_not_actual(resource_id)

        # Проверяем, что были выполнены правильные запросы
        self.assertEqual(self.mock_cursor.execute.call_count, 2)

        # Проверяем запрос на обновление директорий
        dir_call = self.mock_cursor.execute.call_args_list[0]
        self.assertIn("UPDATE directory", dir_call[0][0])
        self.assertEqual(dir_call[0][1], (resource_id,))

        # Проверяем запрос на обновление файлов
        file_call = self.mock_cursor.execute.call_args_list[1]
        self.assertIn("UPDATE file", file_call[0][0])
        self.assertEqual(file_call[0][1], (resource_id,))

    def test_save_files(self):
        # Тестируем метод save_files
        test_files = [
            FileItem(
                directory_s=1,
                information_resource_s=1,
                name="test.txt",
                relative_path="test.txt",
                nesting_level=1,
                owner="user",
                creation_time=datetime.now(),
                modification_time=datetime.now(),
                last_access_time=datetime.now(),
                size_bytes=100,
                md5_hash="abcdef123456"
            )
        ]

        self.database.save_files(test_files)

        # Проверяем, что execute_values был вызван
        self.mock_cursor.execute.assert_called_once()

        # Проверяем, что был выполнен запрос с правильными данными
        call_args = self.mock_cursor.execute.call_args[0]
        self.assertIn("INSERT INTO file", call_args[0])

class TestFileSystemScanner(unittest.TestCase):
    def setUp(self):
        # Создаем временную директорию для тестовых файлов
        self.temp_dir = tempfile.mkdtemp()

        # Создаем мок для базы данных
        self.mock_db = MagicMock()

        # Создаем экземпляр сканера
        self.config = ScannerConfig(batch_size=10, max_workers=1)
        self.scanner = FileSystemScanner(self.config, self.mock_db)

        # Мокаем метод _save_directory для предотвращения реальных запросов к БД
        self.scanner._save_directory = MagicMock(return_value=1)

    def tearDown(self):
        # Удаляем временную директорию после завершения тестов
        shutil.rmtree(self.temp_dir)

    def test_check_path_accessibility_existing_path(self):
        # Проверяем доступность существующего пути
        result = self.scanner._check_path_accessibility(self.temp_dir)
        self.assertTrue(result)

    def test_check_path_accessibility_nonexistent_path(self):
        # Проверяем обработку несуществующего пути
        result = self.scanner._check_path_accessibility("/nonexistent/path")
        self.assertFalse(result)

    def test_check_path_accessibility_file_not_dir(self):
        # Проверяем обработку файла (не директории)
        test_file = Path(self.temp_dir) / "test.txt"
        test_file.touch()
        result = self.scanner._check_path_accessibility(str(test_file))
        self.assertFalse(result)

    @patch('os.stat')
    @patch('pwd.getpwuid')
    def test_get_owner(self, mock_getpwuid, mock_stat):
        # Настраиваем моки
        mock_pwd_entry = MagicMock()
        mock_pwd_entry.pw_name = "testuser"
        mock_getpwuid.return_value = mock_pwd_entry

        # Тестируем метод _get_owner
        owner = self.scanner._get_owner(1000)

        # Проверяем результат
        self.assertEqual(owner, "testuser")
        mock_getpwuid.assert_called_once_with(1000)

    @patch('pwd.getpwuid')
    def test_get_owner_error(self, mock_getpwuid):
        # Настраиваем мок для имитации ошибки
        mock_getpwuid.side_effect = KeyError("Unknown UID")

        # Тестируем метод _get_owner
        owner = self.scanner._get_owner(9999)

        # Проверяем, что метод вернул строковое представление UID
        self.assertEqual(owner, "9999")

    @patch('scanner.scanner.HashCalculator.calculate_md5')
    def test_process_file(self, mock_calculate_md5):
        # Настраиваем мок для метода calculate_md5
        mock_calculate_md5.return_value = "abcdef123456"

        # Создаем тестовый файл и FileItem
        test_file_path = Path(self.temp_dir) / "test_process.txt"
        test_file_path.write_text("test content")

        file_item = FileItem(
            directory_s=1,
            information_resource_s=1,
            name=test_file_path.name,
            relative_path=test_file_path.name,
            nesting_level=1,
            owner="user",
            creation_time=datetime.now(),
            modification_time=datetime.now(),
            last_access_time=datetime.now(),
            size_bytes=100
        )

        # Вызываем метод _process_file
        self.scanner._process_file(file_item, test_file_path)

        # Проверяем, что hash_calculator.calculate_md5 был вызван с правильными параметрами
        mock_calculate_md5.assert_called_once_with(test_file_path)

        # Проверяем, что MD5 хеш был корректно установлен
        self.assertEqual(file_item.md5_hash, "abcdef123456")

    def test_scan_resource_basic(self):
        # Создаем простую структуру файлов для тестирования
        test_dir = Path(self.temp_dir) / "scan_test"
        test_dir.mkdir()

        # Создаем несколько файлов
        (test_dir / "file1.txt").write_text("content 1")
        (test_dir / "file2.txt").write_text("content 2")

        # Создаем поддиректорию с файлами
        subdir = test_dir / "subdir"
        subdir.mkdir()
        (subdir / "file3.txt").write_text("content 3")

        # Запускаем сканирование
        resource_id = 1
        result = self.scanner.scan_resource(
            resource_id=resource_id,
            mount_path=str(test_dir)
        )

        # Проверяем результат сканирования
        self.assertTrue(result)

        # Проверяем, что mark_items_not_actual был вызван
        self.mock_db.mark_items_not_actual.assert_called_once_with(resource_id)

        # Проверяем, что save_files был вызван нужное количество раз
        # (один раз для файлов в корневой директории, один раз для файлов в поддиректории)
        self.assertEqual(self.mock_db.save_files.call_count, 2)

    def test_scan_resource_access_error(self):
        # Проверяем обработку ошибки доступа
        with patch('scanner.scanner.FileSystemScanner._check_path_accessibility', return_value=False):
            result = self.scanner.scan_resource(
                resource_id=1,
                mount_path="/some/path"
            )

            # Сканирование должно завершиться с ошибкой
            self.assertFalse(result)

            # mark_items_not_actual не должен быть вызван
            self.mock_db.mark_items_not_actual.assert_not_called()

    def test_scan_resource_with_domain_path(self):
        # Создаем структуру директорий для тестирования с доменным путем
        test_dir = Path(self.temp_dir) / "resource_test"
        test_dir.mkdir()

        # Создаем доменный путь
        domain_dir = test_dir / "domain"
        domain_dir.mkdir()
        (domain_dir / "domain_file.txt").write_text("domain content")

        # Запускаем сканирование с указанием доменного пути
        resource_id = 2
        result = self.scanner.scan_resource(
            resource_id=resource_id,
            mount_path=str(test_dir),
            domain_path="domain"
        )

        # Проверяем результат сканирования
        self.assertTrue(result)

        # Проверяем, что mark_items_not_actual был вызван
        self.mock_db.mark_items_not_actual.assert_called_once_with(resource_id)

        # Проверяем, что save_files был вызван
        self.mock_db.save_files.assert_called_once()

    @patch('os.stat')
    def test_scan_directory_permission_error(self, mock_stat):
        # Настраиваем мок для имитации ошибки доступа при чтении директории
        def list_dir_side_effect(*args, **kwargs):
            raise PermissionError("Access denied")

        # Создаем тестовую директорию
        test_dir = Path(self.temp_dir) / "perm_error"
        test_dir.mkdir()

        # Патчим метод iterdir для симуляции ошибки доступа
        with patch('pathlib.Path.iterdir', side_effect=list_dir_side_effect):
            # Создаем необходимые переменные для вызова _scan_directory
            resource_id = 3
            parent_dir_map = {}

            # Вызываем метод _scan_directory
            self.scanner._scan_directory(
                resource_id=resource_id,
                directory_path=test_dir,
                parent_dir_map=parent_dir_map,
                parent_directory_s=None,
                relative_base=test_dir,
                nesting_level=0
            )

            # Проверяем, что _save_directory был вызван для основной директории
            self.scanner._save_directory.assert_called_once()

            # Проверяем, что save_files не был вызван, так как не удалось прочитать содержимое директории
            self.mock_db.save_files.assert_not_called()

class TestIntegrationScanner(unittest.TestCase):
    """Интеграционные тесты сканера с использованием временной БД"""

    @classmethod
    def setUpClass(cls):
        # Настройка тестовой базы данных
        cls.db_name = "test_file_structure_db"
        cls.system_dsn = "postgresql://postgres:postgres@localhost:5432/postgres"
        cls.test_dsn = f"postgresql://postgres:postgres@localhost:5432/{cls.db_name}"

        # Создание тестовой базы
        conn = psycopg2.connect(cls.system_dsn)
        conn.autocommit = True
        cursor = conn.cursor()
        cursor.execute(f"DROP DATABASE IF EXISTS {cls.db_name}")
        cursor.execute(f"CREATE DATABASE {cls.db_name}")
        conn.close()

        # Создание необходимых таблиц в тестовой базе
        conn = psycopg2.connect(cls.test_dsn)
        cursor = conn.cursor()

        # Таблица информационных ресурсов
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS information_resource (
                information_resource_s SERIAL PRIMARY KEY,
                data_domain_s INTEGER,
                path VARCHAR(255),
                name VARCHAR(255),
                path_to_mount VARCHAR(255),
                data_domain_path VARCHAR(255)
            )
        """)

        # Таблица директорий
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS directory (
                directory_s SERIAL PRIMARY KEY,
                information_resource_s INTEGER NOT NULL,
                parent_directory_s INTEGER,
                name VARCHAR(255) NOT NULL,
                relative_path VARCHAR(4096) NOT NULL,
                nesting_level INTEGER NOT NULL,
                first_discovered TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
                owner VARCHAR(255),
                is_actual BOOLEAN NOT NULL DEFAULT TRUE,
                UNIQUE (information_resource_s, relative_path)
            )
        """)

        # Таблица файлов
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS file (
                file_s SERIAL PRIMARY KEY,
                directory_s INTEGER NOT NULL,
                information_resource_s INTEGER NOT NULL,
                name VARCHAR(255) NOT NULL,
                relative_path VARCHAR(4096) NOT NULL,
                nesting_level INTEGER NOT NULL,
                first_discovered TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
                creation_time TIMESTAMP,
                modification_time TIMESTAMP,
                last_access_time TIMESTAMP,
                size_bytes BIGINT NOT NULL,
                md5_hash VARCHAR(32),
                owner VARCHAR(255),
                is_actual BOOLEAN NOT NULL DEFAULT TRUE,
                hard_links INTEGER NOT NULL DEFAULT 1,
                UNIQUE (information_resource_s, relative_path)
            )
        """)

        conn.commit()
        conn.close()

    @classmethod
    def tearDownClass(cls):
        # Удаление тестовой базы
        conn = psycopg2.connect(cls.system_dsn)
        conn.autocommit = True
        cursor = conn.cursor()
        cursor.execute(f"DROP DATABASE IF EXISTS {cls.db_name}")
        conn.close()

    def setUp(self):
        # Создаем временную директорию для тестовых файлов
        self.temp_dir = tempfile.mkdtemp()

        # Создаем базу данных и сканер
        self.database = Database(self.test_dsn)
        self.database.connect()

        self.config = ScannerConfig(batch_size=10, max_workers=2)
        self.scanner = FileSystemScanner(self.config, self.database)

        # Добавляем тестовый ресурс в базу данных
        with self.database.transaction() as cursor:
            cursor.execute("""
                INSERT INTO information_resource (
                    information_resource_s, data_domain_s, path, name, path_to_mount
                ) VALUES (%s, %s, %s, %s, %s)
            """, (1, 1, '//test/share', 'Test Resource', self.temp_dir))

    def tearDown(self):
        # Удаляем временную директорию
        shutil.rmtree(self.temp_dir)

        # Очищаем таблицы базы данных
        with self.database.transaction() as cursor:
            cursor.execute("DELETE FROM file")
            cursor.execute("DELETE FROM directory")

        # Закрываем соединение с базой данных
        self.database.close()

    def test_full_scan_integration(self):
        # Создаем тестовую структуру файлов
        test_dir = Path(self.temp_dir)

        # Создаем файлы в корневой директории
        (test_dir / "root_file1.txt").write_text("root content 1")
        (test_dir / "root_file2.txt").write_text("root content 2")

        # Создаем поддиректории с файлами
        subdir1 = test_dir / "subdir1"
        subdir1.mkdir()
        (subdir1 / "sub1_file1.txt").write_text("sub1 content 1")

        subdir2 = test_dir / "subdir2"
        subdir2.mkdir()
        (subdir2 / "sub2_file1.txt").write_text("sub2 content 1")
        (subdir2 / "sub2_file2.txt").write_text("sub2 content 2")

        # Создаем вложенную директорию
        nested_dir = subdir2 / "nested"
        nested_dir.mkdir()
        (nested_dir / "nested_file.txt").write_text("nested content")

        # Запускаем сканирование
        result = self.scanner.scan_resource(resource_id=1, mount_path=str(test_dir))

        # Проверяем результат сканирования
        self.assertTrue(result)

        # Проверяем результаты сканирования в базе данных
        with self.database.transaction() as cursor:
            # Проверяем количество директорий
            cursor.execute("SELECT COUNT(*) FROM directory WHERE information_resource_s = 1")
            dir_count = cursor.fetchone()[0]
            self.assertEqual(dir_count, 3)  # subdir1, subdir2, nested

            # Проверяем количество файлов
            cursor.execute("SELECT COUNT(*) FROM file WHERE information_resource_s = 1")
            file_count = cursor.fetchone()[0]
            self.assertEqual(file_count, 6)  # 2 в корне, 1 в subdir1, 2 в subdir2, 1 в nested

            # Проверяем уровни вложенности
            cursor.execute("""
                SELECT nesting_level, COUNT(*) 
                FROM directory 
                WHERE information_resource_s = 1 
                GROUP BY nesting_level 
                ORDER BY nesting_level
            """)
            nesting_counts = cursor.fetchall()
            self.assertEqual(len(nesting_counts), 2)  # Два уровня вложенности
            self.assertEqual(nesting_counts[0][0], 0)  # Первый уровень (subdir1, subdir2)
            self.assertEqual(nesting_counts[0][1], 2)  # Две директории на уровне 0
            self.assertEqual(nesting_counts[1][0], 1)  # Второй уровень (nested)
            self.assertEqual(nesting_counts[1][1], 1)  # Одна директория на уровне 1

    def test_incremental_scan_integration(self):
        # Создаем начальную структуру файлов
        test_dir = Path(self.temp_dir)
        (test_dir / "initial.txt").write_text("initial content")

        # Первое сканирование
        self.scanner.scan_resource(resource_id=1, mount_path=str(test_dir))

        # Проверяем результаты первого сканирования
        with self.database.transaction() as cursor:
            cursor.execute("SELECT COUNT(*) FROM file WHERE information_resource_s = 1")
            initial_count = cursor.fetchone()[0]
            self.assertEqual(initial_count, 1)

        # Добавляем новый файл
        (test_dir / "new_file.txt").write_text("new content")

        # Изменяем существующий файл
        (test_dir / "initial.txt").write_text("modified content")

        # Ждем, чтобы гарантировать различие во времени модификации
        time.sleep(0.1)

        # Второе сканирование
        self.scanner.scan_resource(resource_id=1, mount_path=str(test_dir))

        # Проверяем результаты второго сканирования
        with self.database.transaction() as cursor:
            # Проверяем общее количество файлов
            cursor.execute("SELECT COUNT(*) FROM file WHERE information_resource_s = 1")
            new_count = cursor.fetchone()[0]
            self.assertEqual(new_count, 2)

            # Проверяем актуальность файлов
            cursor.execute("SELECT COUNT(*) FROM file WHERE information_resource_s = 1 AND is_actual = TRUE")
            actual_count = cursor.fetchone()[0]
            self.assertEqual(actual_count, 2)

            # Проверяем MD5 хеш измененного файла
            cursor.execute("""
                SELECT md5_hash FROM file 
                WHERE information_resource_s = 1 AND name = 'initial.txt'
            """)
            md5_hash = cursor.fetchone()[0]
            expected_hash = hashlib.md5("modified content".encode()).hexdigest()
            self.assertEqual(md5_hash, expected_hash)

    def test_deleted_files_integration(self):
        # Создаем начальную структуру файлов
        test_dir = Path(self.temp_dir)
        (test_dir / "file_to_keep.txt").write_text("keep content")
        (test_dir / "file_to_delete.txt").write_text("delete content")

        # Первое сканирование
        self.scanner.scan_resource(resource_id=1, mount_path=str(test_dir))

        # Проверяем результаты первого сканирования
        with self.database.transaction() as cursor:
            cursor.execute("SELECT COUNT(*) FROM file WHERE information_resource_s = 1")
            initial_count = cursor.fetchone()[0]
            self.assertEqual(initial_count, 2)

        # Удаляем один файл
        (test_dir / "file_to_delete.txt").unlink()

        # Второе сканирование
        self.scanner.scan_resource(resource_id=1, mount_path=str(test_dir))

        # Проверяем результаты второго сканирования
        with self.database.transaction() as cursor:
            # Проверяем общее количество файлов (должно быть все еще 2, но один неактуальный)
            cursor.execute("SELECT COUNT(*) FROM file WHERE information_resource_s = 1")
            total_count = cursor.fetchone()[0]
            self.assertEqual(total_count, 2)

            # Проверяем количество актуальных файлов
            cursor.execute("SELECT COUNT(*) FROM file WHERE information_resource_s = 1 AND is_actual = TRUE")
            actual_count = cursor.fetchone()[0]
            self.assertEqual(actual_count, 1)

            # Проверяем неактуальный файл
            cursor.execute("""
                SELECT name, is_actual FROM file 
                WHERE information_resource_s = 1 AND is_actual = FALSE
            """)
            deleted_file = cursor.fetchone()
            self.assertEqual(deleted_file[0], "file_to_delete.txt")
            self.assertFalse(deleted_file[1])

if __name__ == '__main__':
    unittest.main()
```

## Особенности тестов для синхронной версии

1. **Использование стандартного модуля `unittest`**вместо `pytest` для упрощения совместимости с Python 3.8.
    
2. **Модульные тесты для каждого компонента**:
    
    - Тесты для `HashCalculator`
    - Тесты для `Database` с использованием моков
    - Тесты для `FileSystemScanner` с моками для изоляции от базы данных
3. **Интеграционные тесты** с использованием реальной PostgreSQL базы данных:
    
    - Проверка полного сканирования
    - Проверка инкрементального сканирования
    - Проверка обработки удаленных файлов
4. **Временные директории и файлы** для безопасных тестов файловой системы.
    
5. **Мокирование системных вызовов** для симуляции различных сценариев:
    
    - Ошибки доступа
    - Отсутствие файлов
    - Ошибки чтения
6. **Проверка граничных условий**:
    
    - Пустые файлы
    - Большие файлы
    - Глубоко вложенные директории
    - Отсутствующие пути
7. **Тестирование потокобезопасности** - проверка корректности работы с многопоточностью.
    

## Запуск тестов

```bash
# Основной запуск всех тестов
python -m unittest discover -s tests

# Запуск конкретного тестового класса
python -m unittest tests.test_scanner_sync.TestHashCalculator

# Запуск с покрытием кода
python -m coverage run -m unittest discover -s tests
python -m coverage report -m
python -m coverage html
```

## Примечания

1. Для запуска интеграционных тестов необходим доступ к PostgreSQL с возможностью создания тестовых баз данных.
    
2. Для тестов требуются стандартные библиотеки Python и дополнительно:
    
    ```
    pip install psycopg2-binary coverage
    ```
    
3. Обратите внимание, что интеграционные тесты создают и удаляют тестовую базу данных, поэтому убедитесь, что:
    
    - У пользователя PostgreSQL есть соответствующие права
    - Указаны корректные данные для подключения
    - Тесты не влияют на существующие базы данных
4. Вы можете отключить интеграционные тесты, если нет доступа к PostgreSQL:

```python
@unittest.skip("Requires PostgreSQL")
class TestIntegrationScanner(unittest.TestCase):
   # ...
```
